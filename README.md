# optimal-llm

![python](https://img.shields.io/badge/python-3.9%2B-blue?logo=python)
![pytorch](https://img.shields.io/badge/PyTorch-2.x-%23EE4C2C?logo=pytorch)
![license](https://img.shields.io/badge/license-Apache%202.0-green)

å¤§è¦æ¨¡ Transformer è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ **ç ”ç©¶ç”¨é€”ã§ç´ æ—©ãå®Ÿé¨“** ã§ãã‚‹è»½é‡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚  
Multi-Query Attention + ALiBi å®Ÿè£…ã‚’ç‰¹å¾´ã¨ã—ã€SentencePiece ãƒ™ãƒ¼ã‚¹ã® **æ‹¡å¼µãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼** ã¨ DeepSpeed ã«æœ€é©åŒ–ã—ãŸ **å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** ã‚’åŒæ¢±ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œä¸€æœ¬ã§ *Tokenizer â†’ Pre-training â†’ Inference* ã¾ã§å®Œçµã—ã¾ã™ã€‚

## âœ¨ ä¸»ãªç‰¹å¾´

| æ©Ÿèƒ½ | èª¬æ˜ |
|------|------|
| **Multi-Query Attention with ALiBi** | ãƒˆãƒ¼ã‚¯ãƒ³é•· 65 k ã¾ã§é«˜é€Ÿã«æ‰±ãˆã‚‹æ³¨æ„æ©Ÿæ§‹ã‚’è‡ªå‰å®Ÿè£…ã€‚ãƒ˜ãƒƒãƒ‰ã”ã¨ã«ç·šå½¢ãƒã‚¤ã‚¢ã‚¹ã‚’ä»˜ä¸ã™ã‚‹ ALiBi ã‚‚æ¨™æº–å¯¾å¿œã€‚:contentReference[oaicite:0]{index=0}:contentReference[oaicite:1]{index=1} |
| **SwiGLU FFN + LayerNorm** | æ¨™æº– Transformer ã‚’è»½é‡åŒ–ã—ãªãŒã‚‰è¡¨ç¾åŠ›ã‚’ç¶­æŒã€‚:contentReference[oaicite:2]{index=2}:contentReference[oaicite:3]{index=3} |
| **EnhancedTokenizer** | URL/æ•°å€¤ãƒã‚¹ã‚­ãƒ³ã‚°ãƒ»ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ç¢ºä¿ãƒ»å®Ÿè¡Œæ™‚æ‹¡å¼µãƒ»ãƒˆãƒ¼ã‚¯ãƒ³çµ±è¨ˆãªã©ã€å®Ÿå‹™ã§æ¬²ã—ã‹ã£ãŸ SentecePiece ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ä¸€å¼ã€‚:contentReference[oaicite:4]{index=4}:contentReference[oaicite:5]{index=5} |
| **OptimizedPretrainer** | DeepSpeed Stage-3+ZeRO, å‹¾é…ç´¯ç©ã€ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥é‡ã¿ä»˜ã‘æå¤±ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥é«˜é€ŸåŒ–ã‚’å®Ÿè£…ã€‚:contentReference[oaicite:6]{index=6}:contentReference[oaicite:7]{index=7} |
| **Safetensors save / load** | ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å®‰å…¨ï¼†é«˜é€Ÿã«ä¿å­˜ã€‚ |

## ğŸ“¦ ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

```bash
pip install torch>=2.0 deepspeed sentencepiece safetensors tqdm
# æ¤œç´¢ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æœ‰åŠ¹ã«ã—ãŸã„å ´åˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
pip install tavily-python

from optimal_llm import EnhancedTokenizer, TokenizerConfig

tokenizer = EnhancedTokenizer.train(
    corpus_files=["./corpus/wiki.txt", "./corpus/books.txt"],
    output_dir="./tokenizer_model",
    config=TokenizerConfig(vocab_size=65536),
    additional_special_tokens=["[IMG]"]
)

from optimal_llm import PretrainingConfig, OptimizedPretrainer

cfg = PretrainingConfig()
pretrainer = OptimizedPretrainer(cfg)
pretrainer.train()

from optimal_llm import OptimalLLMModel, EnhancedTokenizer
tok = EnhancedTokenizer.load("./tokenizer_model")
model = OptimalLLMModel.from_pretrained("./checkpoints/step_100000").eval()

prompt = "Q: å¤§é˜ªåŸã¯ã©ã“ã«ã‚ã‚Šã¾ã™ã‹ï¼Ÿ\nA:"
print(model.generate(tok, prompt, max_new_tokens=40))

optimal_llm/
â”œâ”€ optimal_llm.py        # ãƒ¡ã‚¤ãƒ³å®Ÿè£…
â”œâ”€ examples/             # ä½¿ã„æ–¹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€ data/                 # (ä»»æ„) ã‚³ãƒ¼ãƒ‘ã‚¹é…ç½®
â””â”€ checkpoints/          # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«

